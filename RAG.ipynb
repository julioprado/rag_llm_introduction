{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93e133e",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fee2e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_cohere import CohereEmbeddings #faz o embedd\n",
    "from langchain_community.document_loaders import TextLoader # permite carregar arquivos de texto\n",
    "from langchain_text_splitters import CharacterTextSplitter #etapa de fatiamento dos textos em partes menores\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore #permite armazenar os vetores no pinecone\n",
    "from langchain.memory import ConversationBufferMemory #buffer para uma memoria\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8e248",
   "metadata": {},
   "source": [
    "## Carregar vari√°veis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4185785",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv (find_dotenv())\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0362065",
   "metadata": {},
   "source": [
    "## Iniciando o banco de dados do PINECONE\n",
    "OBS: primeito devemos criar o index no pinecone cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baec091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"rag-demo\"\n",
    "embeddings = CohereEmbeddings (\n",
    "\n",
    "    model=\"embed-english-v3.0\",\n",
    "    cohere_api_key=COHERE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad136f73",
   "metadata": {},
   "source": [
    "## Criando mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7139a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julio\\AppData\\Local\\Temp\\ipykernel_12608\\1007421997.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory (\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory (\n",
    "    memory_key= \"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a515d1b3",
   "metadata": {},
   "source": [
    "## Carregamento/Ingest√£o do documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01f7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî•Carregando os documentos...\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\Julio\\AppData\\Local\\Temp\\ipykernel_12608\\1538008509.py:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  PATH_FILE = \"E:\\DNC\\Projeto Houer\\Arquivos Projeto Houer\\mediumblog1.txt\"\n"
     ]
    }
   ],
   "source": [
    "print(\"üî•Carregando os documentos...\\n\\n\")\n",
    "\n",
    "PATH_FILE = \"E:\\DNC\\Projeto Houer\\Arquivos Projeto Houer\\mediumblog1.txt\"\n",
    "loader = TextLoader(PATH_FILE)\n",
    "document = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82faab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'E:\\\\DNC\\\\Projeto Houer\\\\Arquivos Projeto Houer\\\\mediumblog1.txt'}, page_content='Title: Vector Database: What is it and Why You Should Know It?\\n\\nAuthor: Ejiro Onose\\nDate: December 22, 2023\\n\\nIf 2021 was the year of graph databases, 2023 is the year of vector databases √¢‚Ç¨‚Äù Chip Huen.\\n\\nGenerative AI and Large Language Models (LLMs) have become popular, and a vector database is one of the best tools to handle LLM data. Vector databases provide the ideal infrastructure for managing the complex, high-dimensional data that LLMs produce and rely upon.\\n\\nIn this article, I√¢‚Ç¨‚Ñ¢ll explain what vector databases are, how they work, and introduce some top vector database tools.\\n\\n What is a Vector?\\nIn machine learning (ML), a vector is a collection of numerical values that represents the features of multi-dimensional objects, such as words or images. For example, a vector representing an image might contain values related to pixel intensities and color channels.\\n\\n What are Embeddings?\\nAn embedding is a technique for representing complex data (e.g., images, text, audio) as numerical vectors. These vectors capture the semantic similarity between different objects, making similar objects appear closer in vector space. Embeddings are essential in ML applications for tasks like clustering and anomaly detection, and vector databases efficiently store and query these embeddings.\\n\\nNote: An embedding is a vector representation, but not all vectors are embeddings.\\n\\n What is a Vector Database?\\nA vector database stores and manages unstructured data (e.g., text, images, audio) in high-dimensional vectors, enabling efficient retrieval of similar objects at scale. They use vector similarity search algorithms to quickly compare and retrieve data.\\n\\nVector databases are valuable in various applications, from recommender systems to supporting long-term memory in LLM applications, text understanding, and drug discovery.\\n\\n Benefits of Vector Databases\\n1. Handling Massive Data Loads: Vector databases can manage the extensive data generated by LLMs and generative AI.\\n2. Efficient Similarity Searches: Ideal for tasks like image search and content recommendation.\\n3. Integration with ML Algorithms: Allows seamless storage and retrieval of data relevant to ML models.\\n4. Handling Vector Embeddings: Superior for managing embeddings with real-time updates, security, and scalability.\\n\\n Popular Vector Databases\\nHere are some top vector database solutions:\\n\\n- Weaviate: Open-source, supports various data modalities, and integrates with popular ML frameworks.\\n- Pinecone: Fully managed, scalable, and secure; ideal for large ML applications.\\n- Chroma DB: Open-source with self-hosted options, supports in-memory and persistent storage.\\n- Qdrant: Offers disk-stored collections and supports complex query conditions.\\n- Milvus: Open-source with a distributed architecture; handles trillions of vectors and high query throughput.\\n\\n How to Choose the Right Vector Database\\nConsider the following factors:\\n- Scalability for large datasets.\\n- Performance for fast query execution.\\n- Security for robust data protection.\\n- Cost to ensure affordability.\\n- Query Interfaces for ease of interaction.\\n- Deployment Options and Integration Capabilities with existing LLM infrastructure.\\n\\nConclusion\\nVector databases are essential for building LLM applications, offering efficient management of high-dimensional data. Let me know your thoughts on the vector databases mentioned here, and feel free to share your experiences with them.\\n\\nHappy Building!\\n\\n\\nEjiro Onose\\n')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7db9c1",
   "metadata": {},
   "source": [
    "## Fatiamento/ Splinting dos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b1caa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de partes criadas: 5\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(document)\n",
    "print(f\"Total de partes criadas: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c918e",
   "metadata": {},
   "source": [
    "## INSTANCIAR BANCO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6509e377",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No active indexes found in your Pinecone project, are you sure you're using the right Pinecone API key and Environment? Please double check your Pinecone dashboard.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vectorstore_from_docs = \u001b[43mPineconeVectorStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julio\\rag_llm_introduction\\.venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:847\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    844\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    845\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julio\\rag_llm_introduction\\.venv\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:822\u001b[39m, in \u001b[36mPineconeVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, id_prefix, **kwargs)\u001b[39m\n\u001b[32m    777\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     **kwargs: Any,\n\u001b[32m    794\u001b[39m ) -> PineconeVectorStore:\n\u001b[32m    795\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct Pinecone wrapper from raw documents.\u001b[39;00m\n\u001b[32m    796\u001b[39m \n\u001b[32m    797\u001b[39m \u001b[33;03m    This is a user-friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    820\u001b[39m \u001b[33;03m            )\u001b[39;00m\n\u001b[32m    821\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     pinecone_index = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_pinecone_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    823\u001b[39m     pinecone = \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, **kwargs)\n\u001b[32m    825\u001b[39m     pinecone.add_texts(\n\u001b[32m    826\u001b[39m         texts,\n\u001b[32m    827\u001b[39m         metadatas=metadatas,\n\u001b[32m   (...)\u001b[39m\u001b[32m    833\u001b[39m         **(upsert_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    834\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Julio\\rag_llm_introduction\\.venv\\Lib\\site-packages\\langchain_pinecone\\vectorstores.py:765\u001b[39m, in \u001b[36mPineconeVectorStore.get_pinecone_index\u001b[39m\u001b[34m(cls, index_name, pool_threads, pinecone_api_key)\u001b[39m\n\u001b[32m    763\u001b[39m     index = client.Index(index_name)\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index_names) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    766\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo active indexes found in your Pinecone project, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    767\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mare you sure you\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre using the right Pinecone API key and Environment? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    768\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease double check your Pinecone dashboard.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    769\u001b[39m     )\n\u001b[32m    770\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    771\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    772\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in your Pinecone project. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    773\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDid you mean one of the following indexes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(index_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    774\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No active indexes found in your Pinecone project, are you sure you're using the right Pinecone API key and Environment? Please double check your Pinecone dashboard."
     ]
    }
   ],
   "source": [
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    docs, \n",
    "    index_name=index_name, \n",
    "    embedding=embeddings\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
